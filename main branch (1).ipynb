{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d2678d5-ef72-479d-9893-2175c6739a9d",
   "metadata": {},
   "source": [
    "# Обработка pdf-файла"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b15cb3b-114e-4e31-889e-03baaf621735",
   "metadata": {},
   "source": [
    "## Функции"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ea53173-0d9b-4b72-831e-43504be8d41c",
   "metadata": {},
   "source": [
    "### Подключение библиотек, выгрузка всего нужного"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95832a98-90b9-4e70-adcc-cf46959a2fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz  # это pymupdf\n",
    "import re\n",
    "import os\n",
    "import sys\n",
    "import nltk\n",
    "from pathlib import Path\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "nltk_data_path = os.path.join(os.getcwd(), 'nltk_data')\n",
    "nltk.data.path.append(nltk_data_path)\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Лемматизатор\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Стоп-слова для английского (можно добавить стоп-слова для других языков)\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e253fab-096a-46f8-8218-9b78ab40cbbe",
   "metadata": {},
   "source": [
    "### Считывание файла"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4cffc659-f741-4216-a0df-34c0e622f138",
   "metadata": {},
   "outputs": [],
   "source": [
    "def column_boxes(page, footer_margin=50, header_margin=50, no_image_text=True):\n",
    "    \"\"\"Determine bboxes which wrap a column.\"\"\"\n",
    "    paths = page.get_drawings()\n",
    "    bboxes = []\n",
    "\n",
    "    # path rectangles\n",
    "    path_rects = []\n",
    "\n",
    "    # image bboxes\n",
    "    img_bboxes = []\n",
    "\n",
    "    # bboxes of non-horizontal text\n",
    "    # avoid when expanding horizontal text boxes\n",
    "    vert_bboxes = []\n",
    "\n",
    "    # compute relevant page area\n",
    "    clip = +page.rect\n",
    "    clip.y1 -= footer_margin  # Remove footer area\n",
    "    clip.y0 += header_margin  # Remove header area\n",
    "\n",
    "    def can_extend(temp, bb, bboxlist):\n",
    "        for b in bboxlist:\n",
    "            if not intersects_bboxes(temp, vert_bboxes) and (\n",
    "                b == None or b == bb or (temp & b).is_empty\n",
    "            ):\n",
    "                continue\n",
    "            return False\n",
    "\n",
    "        return True\n",
    "\n",
    "    def in_bbox(bb, bboxes):\n",
    "        \"\"\"Return 1-based number if a bbox contains bb, else return 0.\"\"\"\n",
    "        for i, bbox in enumerate(bboxes):\n",
    "            if bb in bbox:\n",
    "                return i + 1\n",
    "        return 0\n",
    "\n",
    "    def intersects_bboxes(bb, bboxes):\n",
    "        \"\"\"Return True if a bbox intersects bb, else return False.\"\"\"\n",
    "        for bbox in bboxes:\n",
    "            if not (bb & bbox).is_empty:\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "    def extend_right(bboxes, width, path_bboxes, vert_bboxes, img_bboxes):\n",
    "\n",
    "        for i, bb in enumerate(bboxes):\n",
    "            # do not extend text with background color\n",
    "            if in_bbox(bb, path_bboxes):\n",
    "                continue\n",
    "\n",
    "            # do not extend text in images\n",
    "            if in_bbox(bb, img_bboxes):\n",
    "                continue\n",
    "\n",
    "            # temp extends bb to the right page border\n",
    "            temp = +bb\n",
    "            temp.x1 = width\n",
    "\n",
    "            # do not cut through colored background or images\n",
    "            if intersects_bboxes(temp, path_bboxes + vert_bboxes + img_bboxes):\n",
    "                continue\n",
    "\n",
    "            # also, do not intersect other text bboxes\n",
    "            check = can_extend(temp, bb, bboxes)\n",
    "            if check:\n",
    "                bboxes[i] = temp  # replace with enlarged bbox\n",
    "\n",
    "        return [b for b in bboxes if b != None]\n",
    "\n",
    "    def clean_nblocks(nblocks):\n",
    "\n",
    "        # 1. remove any duplicate blocks.\n",
    "        blen = len(nblocks)\n",
    "        if blen < 2:\n",
    "            return nblocks\n",
    "        start = blen - 1\n",
    "        for i in range(start, -1, -1):\n",
    "            bb1 = nblocks[i]\n",
    "            bb0 = nblocks[i - 1]\n",
    "            if bb0 == bb1:\n",
    "                del nblocks[i]\n",
    "\n",
    "        # 2. repair sequence in special cases:\n",
    "        # consecutive bboxes with almost same bottom value are sorted ascending\n",
    "        # by x-coordinate.\n",
    "        y1 = nblocks[0].y1  # first bottom coordinate\n",
    "        i0 = 0  # its index\n",
    "        i1 = -1  # index of last bbox with same bottom\n",
    "\n",
    "        # Iterate over bboxes, identifying segments with approx. same bottom value.\n",
    "        # Replace every segment by its sorted version.\n",
    "        for i in range(1, len(nblocks)):\n",
    "            b1 = nblocks[i]\n",
    "            if abs(b1.y1 - y1) > 10:  # different bottom\n",
    "                if i1 > i0:  # segment length > 1? Sort it!\n",
    "                    nblocks[i0 : i1 + 1] = sorted(\n",
    "                        nblocks[i0 : i1 + 1], key=lambda b: b.x0\n",
    "                    )\n",
    "                y1 = b1.y1  # store new bottom value\n",
    "                i0 = i  # store its start index\n",
    "            i1 = i  # store current index\n",
    "        if i1 > i0:  # segment waiting to be sorted\n",
    "            nblocks[i0 : i1 + 1] = sorted(nblocks[i0 : i1 + 1], key=lambda b: b.x0)\n",
    "        return nblocks\n",
    "\n",
    "    # extract vector graphics\n",
    "    for p in paths:\n",
    "        path_rects.append(p[\"rect\"].irect)\n",
    "    path_bboxes = path_rects\n",
    "\n",
    "    # sort path bboxes by ascending top, then left coordinates\n",
    "    path_bboxes.sort(key=lambda b: (b.y0, b.x0))\n",
    "\n",
    "    # bboxes of images on page, no need to sort them\n",
    "    for item in page.get_images():\n",
    "        img_bboxes.extend(page.get_image_rects(item[0]))\n",
    "\n",
    "    # blocks of text on page\n",
    "    blocks = page.get_text(\n",
    "        \"dict\",\n",
    "        flags=fitz.TEXTFLAGS_TEXT,\n",
    "        clip=clip,\n",
    "    )[\"blocks\"]\n",
    "\n",
    "    # Make block rectangles, ignoring non-horizontal text\n",
    "    for b in blocks:\n",
    "        bbox = fitz.IRect(b[\"bbox\"])  # bbox of the block\n",
    "\n",
    "        # ignore text written upon images\n",
    "        if no_image_text and in_bbox(bbox, img_bboxes):\n",
    "            continue\n",
    "\n",
    "        # confirm first line to be horizontal\n",
    "        line0 = b[\"lines\"][0]  # get first line\n",
    "        if line0[\"dir\"] != (1, 0):  # only accept horizontal text\n",
    "            vert_bboxes.append(bbox)\n",
    "            continue\n",
    "\n",
    "        srect = fitz.EMPTY_IRECT()\n",
    "        for line in b[\"lines\"]:\n",
    "            lbbox = fitz.IRect(line[\"bbox\"])\n",
    "            text = \"\".join([s[\"text\"].strip() for s in line[\"spans\"]])\n",
    "            if len(text) > 1:\n",
    "                srect |= lbbox\n",
    "        bbox = +srect\n",
    "\n",
    "        if not bbox.is_empty:\n",
    "            bboxes.append(bbox)\n",
    "\n",
    "    # Sort text bboxes by ascending background, top, then left coordinates\n",
    "    bboxes.sort(key=lambda k: (in_bbox(k, path_bboxes), k.x0, k.y0))\n",
    "\n",
    "    # Extend bboxes to the right where possible\n",
    "    bboxes = extend_right(\n",
    "        bboxes, int(page.rect.width), path_bboxes, vert_bboxes, img_bboxes\n",
    "    )\n",
    "\n",
    "    # immediately return of no text found\n",
    "    if bboxes == []:\n",
    "        return []\n",
    "\n",
    "    # the final block bboxes on page\n",
    "    nblocks = [bboxes[0]]  # pre-fill with first bbox\n",
    "    bboxes = bboxes[1:]  # remaining old bboxes\n",
    "\n",
    "    for i, bb in enumerate(bboxes):  # iterate old bboxes\n",
    "        check = False  # indicates unwanted joins\n",
    "\n",
    "        # check if bb can extend one of the new blocks\n",
    "        for j in range(len(nblocks)):\n",
    "            nbb = nblocks[j]  # a new block\n",
    "\n",
    "            # never join across columns\n",
    "            if bb == None or nbb.x1 < bb.x0 or bb.x1 < nbb.x0:\n",
    "                continue\n",
    "\n",
    "            # never join across different background colors\n",
    "            if in_bbox(nbb, path_bboxes) != in_bbox(bb, path_bboxes):\n",
    "                continue\n",
    "\n",
    "            temp = bb | nbb  # temporary extension of new block\n",
    "            check = can_extend(temp, nbb, nblocks)\n",
    "            if check == True:\n",
    "                break\n",
    "\n",
    "        if not check:  # bb cannot be used to extend any of the new bboxes\n",
    "            nblocks.append(bb)  # so add it to the list\n",
    "            j = len(nblocks) - 1  # index of it\n",
    "            temp = nblocks[j]  # new bbox added\n",
    "\n",
    "        # check if some remaining bbox is contained in temp\n",
    "        check = can_extend(temp, bb, bboxes)\n",
    "        if check == False:\n",
    "            nblocks.append(bb)\n",
    "        else:\n",
    "            nblocks[j] = temp\n",
    "        bboxes[i] = None\n",
    "\n",
    "    # do some elementary cleaning\n",
    "    nblocks = clean_nblocks(nblocks)\n",
    "\n",
    "    # return identified text bboxes\n",
    "    return nblocks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e34556f9-86f3-432f-8564-5485b79183cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_paragraphs_from_pdf(pdf_path):\n",
    "    \"\"\"\n",
    "    Извлекает текст из PDF файла и возвращает список абзацев.\n",
    "\n",
    "    :param pdf_path: Путь к PDF файлу.\n",
    "    :return: Список абзацев, где каждый абзац представлен как строка.\n",
    "    \"\"\"\n",
    "    # Открытие PDF документа\n",
    "    doc = fitz.open(pdf_path)\n",
    "\n",
    "    # Переменная для хранения всего извлеченного текста\n",
    "    all_extracted_text = \"\"\n",
    "\n",
    "    # Обработка каждой страницы\n",
    "    for page in doc:\n",
    "        # Получение границ текстовых блоков\n",
    "        bboxes = column_boxes(page, footer_margin=50, no_image_text=True)\n",
    "\n",
    "        # Извлечение текста из каждого блока и добавление в строку\n",
    "        for rect in bboxes:\n",
    "            # Извлекаем текст для текущего прямоугольника\n",
    "            extracted_text = page.get_text(clip=rect, sort=True)\n",
    "            # Добавляем текст в общую строку\n",
    "            all_extracted_text += extracted_text\n",
    "            \n",
    "    return all_extracted_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55313022-e8b2-4ad3-b585-188eda240c8b",
   "metadata": {},
   "source": [
    "### Обработка от исходного текста до списка абзацев"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d46cb29-7350-4bb0-aa22-bf55c5493979",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_paragraphs(paragraphs):\n",
    "    lines = paragraphs.splitlines()  # Разделяем текст на строки\n",
    "    result = []  # Список для хранения обработанных строк\n",
    "\n",
    "    for i in range(len(lines)):\n",
    "        line = lines[i]\n",
    "\n",
    "        # Условие 1: Если строка начинается с пробела, добавляем её без изменений\n",
    "        if line.startswith(' '):\n",
    "            result.append(line)\n",
    "        else:\n",
    "            # Условие 2: Если строка не начинается с пробела и не содержит табуляции\n",
    "            if '  ' not in line:\n",
    "                # Проверяем, что предыдущая строка не пустая\n",
    "                if i > 0 and lines[i - 1].strip():  # Если предыдущая строка не пустая\n",
    "                    # Объединяем текущую строку с предыдущей, убирая переход на новую строку\n",
    "                    result[-1] += ' ' + line.strip()  # Добавляем текущую строку без перехода\n",
    "                    continue  # Переходим к следующей строке\n",
    "            result.append(line)  # Добавляем текущую строку\n",
    "\n",
    "    return '\\n'.join(result)  # Объединяем строки обратно в текст\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c2bb8de5-4c25-4ad8-90e7-2b7a9ec8940c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_and_merge_tabbed_lines(processed_text):\n",
    "    result = []\n",
    "    buffer = []  # Временный буфер для строк с табуляцией\n",
    "\n",
    "    # Удаляем пробелы в начале каждой строки\n",
    "    lines = [line.lstrip() for line in processed_text.splitlines()]\n",
    "\n",
    "    for line in lines:\n",
    "        if '  ' in line:\n",
    "            # Если строка содержит табуляцию, добавляем её в буфер\n",
    "            buffer.append(line)\n",
    "        else:\n",
    "            if buffer:\n",
    "                # Если в буфере есть строки с табуляцией, объединяем их и добавляем в результат\n",
    "                result.append(\"\\n\".join(buffer))\n",
    "                buffer = []  # Очищаем буфер после добавления\n",
    "\n",
    "            # Добавляем обычную строку (без табуляции) в результат\n",
    "            result.append(line)\n",
    "\n",
    "    # Добавляем оставшиеся строки с табуляцией, если они есть в конце текста\n",
    "    if buffer:\n",
    "        result.append(\"\\n\".join(buffer))\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bcc170e3-08a3-4a85-9b6f-bd1e5c9f5605",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_list_elements(lines_list):\n",
    "    result = []\n",
    "\n",
    "    for i, line in enumerate(lines_list):\n",
    "        # Пропускаем пустые элементы\n",
    "        if not line.strip():\n",
    "            continue\n",
    "\n",
    "        # Если это не первый элемент и текущий элемент начинается с маленькой буквы,\n",
    "        # а в предыдущем элементе нет двойного пробела, объединяем с предыдущим\n",
    "        if result and line[0].islower() and '  ' not in result[-1]:\n",
    "            result[-1] = result[-1].rstrip() + ' ' + line.lstrip()\n",
    "        else:\n",
    "            result.append(line)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df0a6f03-6b44-49c9-a395-43ca0bb10c7d",
   "metadata": {},
   "source": [
    "### Лемматизация текста с использованием NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b01c8048-2f92-4706-859e-85a3fe069759",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция для очистки текста: удаление стоп-слов и лемматизация\n",
    "def process_text(text):\n",
    "    # Токенизация\n",
    "    tokens = word_tokenize(text)\n",
    "\n",
    "    # Удаление стоп-слов и лемматизация\n",
    "    cleaned_tokens = [\n",
    "        lemmatizer.lemmatize(word.lower()) for word in tokens\n",
    "        if word.isalnum() and word.lower() not in stop_words  # Убираем стоп-слова и небуквенные токены\n",
    "    ]\n",
    "\n",
    "    return cleaned_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a2f1f1eb-147a-4b00-bd34-099341a7557e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Основная функция поиска\n",
    "def find_near_words(result, processed_list, find):\n",
    "    lemmatized_find = process_text(find)  # Лемматизируем и очищаем find через process_text\n",
    "\n",
    "    found_indices = []  # Список для хранения индексов найденных предложений\n",
    "\n",
    "    for i, sentence_tokens in enumerate(result):  # Здесь sentence_tokens — это уже список слов\n",
    "        if len(lemmatized_find) == 1:  # Если в find только одно слово\n",
    "            # Проверяем наличие этого слова в предложении\n",
    "            if lemmatized_find[0] in sentence_tokens:\n",
    "                found_indices.append(i)  # Если найдено, добавляем индекс предложения\n",
    "        else:\n",
    "            # Ищем, находятся ли леммы из find на расстоянии не более двух слов друг от друга\n",
    "            positions = []\n",
    "            for lemma in lemmatized_find:\n",
    "                if lemma in sentence_tokens:\n",
    "                    positions.append(sentence_tokens.index(lemma))\n",
    "\n",
    "            # Если леммы найдены и их позиции расположены в пределах двух слов друг от друга\n",
    "            if len(positions) == len(lemmatized_find):  # Все леммы найдены\n",
    "                positions.sort()  # Сортируем позиции\n",
    "                if all(abs(positions[i] - positions[i+1]) <= 2 for i in range(len(positions) - 1)):\n",
    "                    found_indices.append(i)  # Добавляем индекс предложения\n",
    "\n",
    "    # Выводим предложения из processed_list с найденными индексами\n",
    "    count=1\n",
    "    for index in found_indices:\n",
    "        print(f\"Совпадение №{count}: {processed_list[index]}\")\n",
    "        count = count+1 \n",
    "    return found_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1591e1a2-f9f5-40f1-8cf5-d26f96d80007",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_pdf_directory(directory_path, find_word):\n",
    "    # Проходим по всем PDF-файлам в директории\n",
    "    for file_path in Path(directory_path).rglob('*.pdf'):\n",
    "        print(f\"\\n=== Работаю с файлом {file_path.name} ===\")\n",
    "        paragraphs = extract_paragraphs_from_pdf(file_path)\n",
    "        processed_text = process_paragraphs(paragraphs)\n",
    "        lines_list = process_and_merge_tabbed_lines(processed_text)\n",
    "        processed_list = process_list_elements(lines_list)\n",
    "        result = [process_text(text) for text in processed_list]\n",
    "        \n",
    "        # Ищем фрагменты\n",
    "        fragments = find_near_words(result, processed_list, find_word)\n",
    "        \n",
    "        # Если есть фрагменты, выводим имя файла и фрагменты\n",
    "        if fragments:\n",
    "            print(f\"\\n=== В файле: {file_path.name} найдено {len(fragments)} совпадений ===\")\n",
    "        print(\"_______________________________________________________________________\")            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f87b45-cfae-4c27-ac6a-5bbbce56009e",
   "metadata": {},
   "source": [
    "## Использование"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d2b019d9-eaa6-42db-952d-61f4f7faeb29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bb524fe8d3149889fb3afcf20891356",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='Файлы', description='Директория:')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb293649bae24bdc9c2549072f3cca46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='global energy', description='Ключевое слово:')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b933b58923d84b8a94464167903f7dbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='success', description='Найти', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "707cd3fd81e54c4a8c4f908b4045dd26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Создаем виджет для вывода\n",
    "out = widgets.Output()\n",
    "\n",
    "# Создаем виджеты для ввода данных\n",
    "directory_input = widgets.Text(\n",
    "    value='Файлы',  # Убедитесь, что директория существует\n",
    "    description='Директория:',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "keyword_input = widgets.Text(\n",
    "    value='global energy',\n",
    "    description='Ключевое слово:',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "# Кнопка для запуска процесса\n",
    "run_button = widgets.Button(\n",
    "    description='Найти',\n",
    "    disabled=False,\n",
    "    button_style='success'  # 'success', 'info', 'warning', 'danger'\n",
    ")\n",
    "\n",
    "# Функция, которая будет вызываться при нажатии на кнопку\n",
    "def on_button_click(b):\n",
    "    directory = directory_input.value\n",
    "    keyword = keyword_input.value\n",
    "\n",
    "    # Очищаем предыдущий вывод перед новым запуском\n",
    "    with out:\n",
    "        out.clear_output()\n",
    "        print(f\"\\nПоиск в директории: {directory}\")\n",
    "        print(f\"Искомое слово: {keyword}\")\n",
    "        \n",
    "        # Запуск процесса обработки PDF\n",
    "        process_pdf_directory(directory, keyword)\n",
    "\n",
    "# Привязываем функцию к кнопке\n",
    "run_button.on_click(on_button_click)\n",
    "\n",
    "# Отображаем элементы управления и место для вывода\n",
    "display(directory_input, keyword_input, run_button, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "07601021-e904-47ea-b0a4-0b9cde83ee62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "++++++++++++++++++++++++++++ Поисковый запрос: Stock ++++++++++++++++++++++++++++\n",
      "\n",
      "=== Работаю с файлом Coal_Trader_International_10_Oct_2024.pdf ===\n",
      "Совпадение №1: A trader in China said that while buyers resumed trades early this week, sufficient existing stocks at ports and power plants limited winter restocking imports. Additionally, predictions of a severe winter due to La Niña have prompted domestic miners to increase output to ensure energy security, a second trader in China said.\n",
      "Совпадение №2: Joseph Mennella, joseph.mennella@spglobal.com   Stocks at China’s major northern ports, including Qinhuangdao, Jingtang and Caofeidian, stood at 23.62 million mt on Oct. 9, down from 23.82 million mt the previous week. The trader attributed this stable stockpile to robust domestic supply from mines.\n",
      "Совпадение №3: Indian industrial demand largely remained subdued, with few coastal plants inquiring about mid-high CV cargoes in anticipation of increased energy consumption next week for the Diwali festival. Data from the Central Electricity Authority showed that six out of 16 imported coal-based power plants were operating with critical stocks, which an Indonesia-based trader believed would prompt some near-term imports. However, most domestic coal-based plants received sufficient supply from local mines, the trader added.\n",
      "Совпадение №4: North China prompt port stock prices                                                 Platts  Ex-stock Jingtang  Platts   CFR Jingtang\n",
      "Совпадение №5: Price spreads                                        Platts symbol        $/mt\n",
      "Import-Shanxi Premium Low Vol CFR China                  PLVHK04        -12.46\n",
      "Import-port stock Premium Low Vol CFR China               PLVHL04         -2.06\n",
      "62/60% CSR coke export-domestic FOB North China         PLVHN04         -3.50Metallurgical coke, Oct 10 Seaborne\n",
      "% CSR  Platts symbol $/mt    Chg  % Chg\n",
      "FOB North China                    66/65     MCCNC00    295.00     0.00     0.00\n",
      "65/63     MCCHB00    285.00     0.00     0.00\n",
      "64/62     AAWVL00    274.00     0.00     0.00\n",
      "62/60     MCCHA00    270.00     0.00     0.00CFR India                          66/65     MCCNI00    299.00     0.00     0.00\n",
      "65/63     MCINB00    289.00     0.00     0.00\n",
      "64/62     MCCEI00    279.00     0.00     0.00\n",
      "62/60     MCINA00    274.00     0.00     0.00Domestic\n",
      "Совпадение №6:    Consumers unwilling to accept higher prices   Persistent weak demand and uncertainty of festive demand rekindling, continued to put pressure on India-delivered petcoke prices in the week to Oct. 9, amid sluggish demand from cement producers and pre-existing stocks, sources said.\n",
      "\n",
      "=== В файле: Coal_Trader_International_10_Oct_2024.pdf найдено 6 совпадений ===\n",
      "_______________________________________________________________________\n",
      "\n",
      "=== Работаю с файлом Coal_Trader_16_Sep_2024.pdf ===\n",
      "Совпадение №1: “It’s still hard for Chinese mills to commit to a full Panamax, and most would prefer to buy port stock in smaller quantities,” a Chinese trader said.\n",
      "Совпадение №2: Thermal coal prices fell in August due to sluggish demand from top importers. Rainfall in China and India, coupled with sufficient stocks at ports, reduced coal buying appetite from India and China, which decreased demand for spot cargoes. Market participants anticipated demand to pick up as rains subside and as China begins restocking for the winter season and building stocks for the upcoming festival season.\n",
      "\n",
      "=== В файле: Coal_Trader_16_Sep_2024.pdf найдено 2 совпадений ===\n",
      "_______________________________________________________________________\n",
      "\n",
      "=== Работаю с файлом Coal_Trader_10_Oct_2024.pdf ===\n",
      "Совпадение №1: joseph.mennella@spglobal.comCoal Trader is published every business day by S&P Global Commodity Insights, a division of S&P Global, registered office: 20 Canada Square, Canary Wharf, London, E14 5LH. Officers of the Corporation: Richard E. Thornburgh, Non-Executive Chairman; Doug Peterson, President and Chief Executive Officer; Christopher Craig Interim Chief Financial Officer; Steve Kemps, Executive Vice President, General Counsel © 2024 by S&P Global Inc. All rights reserved. S&P Global, the S&P Global logo, S&P Global Commodity Insights, and Platts are trademarks of S&P Global Inc. Permission for any commercial use of these trademarks must be obtained in writing from S&P Global Inc. You may view or otherwise use the information, prices, indices, assessments and other related information, graphs, tables and images (“Data”) in this publication only for your personal use or, if you or your company has a license for the Data from S&P Global Commodity Insights and you are an authorized user, for your company’s internal business use only. You may not publish, reproduce, extract, distribute, retransmit, resell, create any derivative work from and/or otherwise provide access to the Data or any portion thereof to any person (either within or outside your company, including as part of or via any internal electronic system or intranet), firm or entity, including any subsidiary, parent, or other entity that is affiliated with your company, without S&P Global Commodity Insights’ prior written consent or as otherwise authorized under license from S&P Global Commodity Insights. Any use or distribution of the Data beyond the express uses authorized in this paragraph above is subject to the payment of additional fees to S&P Global Commodity Insights. S&P Global Commodity Insights, its affiliates and all of their third- party licensors disclaim any and all warranties, express or implied, including, but not limited to, any warranties of   In the South Central region, stocks grew by 24 Bcf in the week ended Oct. 4 to 1.137 Tcf. After a series of pulls and relatively small injections at salt and non-salt storage sites in the region throughout the summer, South Central storage is about 2% above the five-year average, the smallest margin of any of the EIA’s five regions. \n",
      "\n",
      "=== В файле: Coal_Trader_10_Oct_2024.pdf найдено 1 совпадений ===\n",
      "_______________________________________________________________________\n",
      "\n",
      "=== Работаю с файлом Argus_Russian_Coal_(2024-10-07).pdf ===\n",
      "_______________________________________________________________________\n",
      "\n",
      "++++++++++++++++++++++++++++ Поисковый запрос: Bullish ++++++++++++++++++++++++++++\n",
      "\n",
      "=== Работаю с файлом Coal_Trader_International_10_Oct_2024.pdf ===\n",
      "Совпадение №1: Moreover, recent stimulus from the Chinese government has kept sentiment bullish in the domestic market, further supporting high domestic coal prices. Currently, the price for domestic 5,500 kcal/kg NAR is around Yuan 880/mt, up from Yuan 875/mt the previous week, the second trader added.\n",
      "\n",
      "=== В файле: Coal_Trader_International_10_Oct_2024.pdf найдено 1 совпадений ===\n",
      "_______________________________________________________________________\n",
      "\n",
      "=== Работаю с файлом Coal_Trader_16_Sep_2024.pdf ===\n",
      "_______________________________________________________________________\n",
      "\n",
      "=== Работаю с файлом Coal_Trader_10_Oct_2024.pdf ===\n",
      "_______________________________________________________________________\n",
      "\n",
      "=== Работаю с файлом Argus_Russian_Coal_(2024-10-07).pdf ===\n",
      "_______________________________________________________________________\n",
      "\n",
      "++++++++++++++++++++++++++++ Поисковый запрос: bearish ++++++++++++++++++++++++++++\n",
      "\n",
      "=== Работаю с файлом Coal_Trader_International_10_Oct_2024.pdf ===\n",
      "_______________________________________________________________________\n",
      "\n",
      "=== Работаю с файлом Coal_Trader_16_Sep_2024.pdf ===\n",
      "_______________________________________________________________________\n",
      "\n",
      "=== Работаю с файлом Coal_Trader_10_Oct_2024.pdf ===\n",
      "Совпадение №1:    Prompt NYMEX futures at $2.68/MMBtu  The US natural gas market added 82 Bcf to Lower 48 storage inventories in the week ended Oct. 4, the US Energy Information Administration said in an Oct. 10 report that was bearish to analysts’ expectations.\n",
      "\n",
      "=== В файле: Coal_Trader_10_Oct_2024.pdf найдено 1 совпадений ===\n",
      "_______________________________________________________________________\n",
      "\n",
      "=== Работаю с файлом Argus_Russian_Coal_(2024-10-07).pdf ===\n",
      "_______________________________________________________________________\n",
      "\n",
      "++++++++++++++++++++++++++++ Поисковый запрос: coal deficit ++++++++++++++++++++++++++++\n",
      "\n",
      "=== Работаю с файлом Coal_Trader_International_10_Oct_2024.pdf ===\n",
      "_______________________________________________________________________\n",
      "\n",
      "=== Работаю с файлом Coal_Trader_16_Sep_2024.pdf ===\n",
      "_______________________________________________________________________\n",
      "\n",
      "=== Работаю с файлом Coal_Trader_10_Oct_2024.pdf ===\n",
      "_______________________________________________________________________\n",
      "\n",
      "=== Работаю с файлом Argus_Russian_Coal_(2024-10-07).pdf ===\n",
      "_______________________________________________________________________\n",
      "\n",
      "++++++++++++++++++++++++++++ Поисковый запрос: coal proficit ++++++++++++++++++++++++++++\n",
      "\n",
      "=== Работаю с файлом Coal_Trader_International_10_Oct_2024.pdf ===\n",
      "_______________________________________________________________________\n",
      "\n",
      "=== Работаю с файлом Coal_Trader_16_Sep_2024.pdf ===\n",
      "_______________________________________________________________________\n",
      "\n",
      "=== Работаю с файлом Coal_Trader_10_Oct_2024.pdf ===\n",
      "_______________________________________________________________________\n",
      "\n",
      "=== Работаю с файлом Argus_Russian_Coal_(2024-10-07).pdf ===\n",
      "_______________________________________________________________________\n",
      "\n",
      "++++++++++++++++++++++++++++ Поисковый запрос: thermal coal supply ++++++++++++++++++++++++++++\n",
      "\n",
      "=== Работаю с файлом Coal_Trader_International_10_Oct_2024.pdf ===\n",
      "_______________________________________________________________________\n",
      "\n",
      "=== Работаю с файлом Coal_Trader_16_Sep_2024.pdf ===\n",
      "_______________________________________________________________________\n",
      "\n",
      "=== Работаю с файлом Coal_Trader_10_Oct_2024.pdf ===\n",
      "_______________________________________________________________________\n",
      "\n",
      "=== Работаю с файлом Argus_Russian_Coal_(2024-10-07).pdf ===\n",
      "_______________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Директория с PDF-файлами\n",
    "directory = \"Файлы\"\n",
    "\n",
    "# Список поисковых запросов\n",
    "search_queries = [\n",
    "    \"Stock\",\n",
    "    \"Bullish\",\n",
    "    \"bearish\",\n",
    "    \"coal deficit\",\n",
    "    \"coal proficit\",\n",
    "    \"thermal coal supply\"\n",
    "]\n",
    "\n",
    "# Цикл по всем запросам\n",
    "for query in search_queries:\n",
    "    print(f\"\\n++++++++++++++++++++++++++++ Поисковый запрос: {query} ++++++++++++++++++++++++++++\")\n",
    "    process_pdf_directory(directory, query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9412f73-4dcd-4c5c-ac4b-025f19d10aa1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
